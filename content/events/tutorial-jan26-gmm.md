Title: Clustering the Iris Dataset via K-Means
Date: January 26, 2016 5:30 PM
Location: DOW 2166
Category: Tutorial
Summary:  Interested in Machine Learning?  Don't know where to start?  Never fear!  This Tuesday, we'll continue our discussion of clustering. Last Tuesday, we invented and used K-Means to automatically identify flower species.  Today, we'll take a look at K-Means' next of kin: Gaussian Mixtures. A small but important tweak will enable us to cluster datasets far beyond the power of K-Means!  Time permitting, we'll further vary the themes of doubt, iteration, and similarity to understand and apply several related unsupervised learning algorithms.

**Interested in Machine Learning?  Don't know where to start?  Never fear!**  This Tuesday, we'll continue our discussion of clustering. Last Tuesday, we invented and used K-Means to automatically identify flower species.  Today, we'll take a look at K-Means' next of kin: Gaussian Mixtures. A small but important tweak will enable us to cluster datasets far beyond the power of K-Means!  Time permitting, we'll further vary the themes of doubt, iteration, and similarity to understand and apply several related unsupervised learning algorithms.

By the end of our session, you'll:
 * Appreciate the utility of *doubt* in an algorithm, hence entering the Cult of Bayes.
 * Understand multiple clustering algorithms, and when to use which.
 * Enthuse to participate in more of MSAIL's activities!

 **What if I missed last week?** Answer: *come anyway*! We're still on the topic of clustering, so now's the perfect time to catch up. In fact, this week's algorithm is secretly the same as last time's, except for a small but important tweak!