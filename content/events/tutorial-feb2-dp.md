Title: Klustering without the "K"
Date: February 2, 2016 5:30 PM
Location: DOW 2166
Category: Tutorial
Summary:  Interested in Machine Learning?  Don't know where to start?  Never fear!  This Tuesday, we'll continue our discussion of clustering. Last Tuesday, we extended our intuition about clustering and K-Means to a "softer" variant called Gaussian Mixture Modeling.  This week, we'll wrap up our three-week coverage of basic clustering algorithms and introduce a new model, called **Dirichlet Processes**, that automatically decides the optimal number of clusters as it learns.

**Interested in Machine Learning?  Don't know where to start?  Never fear!**  This Tuesday, we'll continue our discussion of clustering. Last Tuesday, we extended our intuition about clustering and K-Means to a "softer" variant called Gaussian Mixture Modeling.  This week, we'll wrap up our three-week coverage of basic clustering algorithms and introduce a new model, called **Dirichlet Processes**, that automatically decides the optimal number of clusters as it learns.

 **What if I missed last week?** Answer: *come anyway*! We're still on the topic of clustering, so now's the perfect time to catch up. In fact, this week's algorithm is secretly the same as last time's, except for a small but important tweak!